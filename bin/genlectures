#!/usr/bin/env ruby

require 'choosy'
require 'uri'
require 'digest'
require 'net/http'
require 'fileutils'
require 'tempfile'

################################################################################
# Main Class that downloads everything

class Downloader
  def initialize(base_url, output_dir, dry_run, course)
    @base_url, @output_dir, @dry_run, @course = base_url, output_dir, dry_run, course
  end

  def download_videos!
    @course['lectures'].each_with_index do |urls, i|
      extension = File.extname(urls[0])

      lecture_name = "Lecture #{i + 1}#{extension}"
      final_lecture = File.join(course_path, lecture_name)
      next if File.exists?(final_lecture)

      lecture_parts = download_videos_from(urls)
      combine_lecture_parts(lecture_parts, final_lecture)
    end
  end

  def download_notes!(browser)
    return unless @course['notes']

    @course['notes'].each do |note|
      uri = if note['url'] =~ /^https?:/
              URI.parse(note['url'])
            else
              URI.join(@base_url, note['url'])
            end

      case note['type']
      when 'website' then download_website!(note, uri, browser)
      when 'directory' then download_directory!(note, uri)
      else
        download_file!(note, uri)
      end
    end
  end

  private
  def download_file!(note, uri)
    file_path = File.join(course_path, "#{note['name']}.#{note['type']}")

    while_unable_to_download(uri, file_path) do
      $stderr.puts "Unable to download file: #{uri.to_s}"
    end

    case note['type']
    when 'ps.gz' then `gunzip #{file_path}` && FileUtils.rm file_path
    when 'zip' then `unzip #{file_path}` && FileUtils.rm file_path
    end
  end

  def download_website!(note, uri, browser)
    website_script = File.join(course_path, "#{note['name']}.sh")

    File.open(website_script, 'w') do |io|
      io.write """#!/bin/bash

set -e
#{browser} #{uri.to_s}
"""
    end

    FileUtils.chmod 0774, website_script
  end

  def download_directory!(note, uri)
    download_directory = File.join(course_path, note['name'])
    FileUtils.mkdir_p(download_directory)

    Net::HTTP.get(uri).scan(/<a href=["'](.*?)['"]/) do |match|
      match.each do |path|
        next unless path =~ /\.(pdf|zip)$/

        local_path = File.join(download_directory, path)
        uri  = URI.join(uri, URI.escape(path))

        while_unable_to_download(uri, local_path) do
          $stderr.puts "Unable to download: #{uri.to_s}"
        end
      end
    end
  end

  def course_name
    "#{@course['name']} - #{@course['speaker']}"
  end

  def course_path
    course_path = File.join(@output_dir, course_name)
    FileUtils.mkdir_p(course_path) unless Dir.exists?(course_path)
    course_path
  end

  def while_unable_to_download(uri, path, &block)
    iteration = 1
    while backoff = try_to_download(uri, path, iteration)
      yield
      $stderr.puts "Retrying in #{backoff} seconds."
      sleep(backoff)
      iteration += 1
    end
  end

  def try_to_download(uri, path, iteration)
    if File.exists?(path)
      $stdout.puts "Already retrieved: #{path}"
      $stdout.puts "             from: #{uri.to_s}"
      return nil
    end

    return nil if @dry_run

    $stdout.puts "Retrieving: #{uri.to_s}"
    $stdout.puts "Writing to: #{path}"

    Net::HTTP.start(uri.host, uri.port) do |http|
      request = Net::HTTP::Get.new uri

      http.request request do |response|
        case response.code
        when /20./ then
          File.open(path, 'w') do |io|
            response.read_body do |chunk|
              io.write chunk
            end
          end

          return nil
        when /40./
          $stderr.puts "FATAL ERROR! Unable to download: #{uri.to_s}"
          return nil
        else
          $stderr.puts "Bad response from server: (#{uri.to_s}) @ #{response.code}"

          backoff = (2.0 ** iteration).to_i

          return backoff
        end
      end
    end
  end

  # Oregon State seems to rate limit their HTTP connections
  THREAD_COUNT = 2

  def download_videos_from(urls)
    result = []
    queue = Queue.new

    urls.each do |url|
      extension = File.extname(url)
      name = Digest::SHA1.new.update(url).to_s
      path = File.join(course_path, "#{name}#{extension}")
      video = URI.join(@base_url, url)

      result << path
      queue << {video: video, path: path}
    end

    threads = THREAD_COUNT.times.map do
      Thread.new do
        while !queue.empty? && item = queue.pop
          while_unable_to_download(item[:video], item[:path]) do
            $stderr.puts "Unable to download video: #{item[:video].to_s}"
          end
        end
      end
    end
    threads.each(&:join)

    result
  end

  def combine_lecture_parts(lecture_parts, output_path)
    $stdout.puts "Combining lecture parts into: '#{output_path}'"
    tmp = Tempfile.new('lectures')
    begin
      lecture_parts.each do |video|
        tmp.write("file '#{Dir.pwd}/#{video}'\n")
      end
      tmp.close

      system "ffmpeg -f concat -i #{tmp.path} -codec copy \"#{output_path}\""
      if $? != 0
        $stderr.puts "Unable to combine mp4 files using ffmpeg."
        exit 1
      else
        lecture_parts.each do |video|
          $stdout.puts "Cleaning up intermediary file: #{video}"
          FileUtils.rm_f(video)
        end
      end
    ensure
      tmp.close!
    end
  end
end

################################################################################
# CLI

$cmd = Choosy::Command.new :genlectures do
  summary "This tool geneates a combined file from the various URLs for videos from the Oregon Summer School project."

  section "Options" do
    yaml :yaml,
      "The YAML file for the year you're interested in.",
      required: true

    string :course,
      "The regular expression that matches by course name. By default it selects all courses.",
      default: '.*'

    string :'out-dir',
      "The directory to put the completed lectures, by year.",
      default: 'lectures'

    boolean :'skip-videos',
      "Skip downloading and colating the videos."

    boolean :'no-notes',
      "Don't download any of the notes."

    boolean :'dry-run',
      "Run through everything but don't do anything.",
      default: false

    string :browser,
      "Whatever browser to use to open external web pages. Defaults to 'firefox'.",
      default: 'firefox'
  end

  help
  version "2015.10"

  executor do |args, options|
    course_match = Regexp.new(options[:course])
    courses = []
    options[:yaml]['courses'].each do |course|
      if course['name'] =~ course_match
        courses << course
      end
    end

    if courses.length == 0
      $stderr.puts "No matching courses"
      exit 1
    end

    out_dir = File.join(options[:'out-dir'], options[:yaml]['year'].to_s)
    FileUtils.mkdir_p(out_dir) unless Dir.exists?(out_dir)

    courses.each do |course|
      downloader = Downloader.new(options[:yaml]['url'], out_dir, options[:'dry_run'], course)
      downloader.download_videos! unless options[:'skip-videos']
      downloader.download_notes!(options[:browser]) unless options[:'no-notes']
    end
  end
end

# main
if __FILE__ == $0
  $cmd.execute!(ARGV)
end
